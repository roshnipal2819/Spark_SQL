{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b943a4-ae0a-4449-ac64-b978f2c4224b",
   "metadata": {},
   "source": [
    "Window functions operate on a group of rows, referred to as a window, and calculate a return value for each row based on the group of rows. Window functions are useful for processing tasks such as calculating a moving average, computing a cumulative statistic, or accessing the value of rows given the relative position of the current row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22de124-52ad-4fde-ae90-2c87ac20c79c",
   "metadata": {},
   "source": [
    "### Syntax\n",
    "\n",
    "window_function [ nulls_option ] OVER\n",
    "( [  { PARTITION | DISTRIBUTE } BY partition_col_name = partition_col_val ( [ , ... ] ) ]\n",
    "  { ORDER | SORT } BY expression [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [ , ... ]\n",
    "  [ window_frame ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347fb177-b67b-43f7-b9ec-568ed0e78c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "879b65f3-358c-433e-9744-d1ec17a36665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+---+\n",
      "| name|       dept|salary|age|\n",
      "+-----+-----------+------+---+\n",
      "| Lisa|      Sales| 10000| 35|\n",
      "| Evan|      Sales| 32000| 38|\n",
      "| Fred|Engineering| 21000| 28|\n",
      "| Alex|      Sales| 30000| 33|\n",
      "|  Tom|Engineering| 23000| 33|\n",
      "| Jane|  Marketing| 29000| 28|\n",
      "| Jeff|  Marketing| 35000| 38|\n",
      "| Paul|Engineering| 29000| 23|\n",
      "|Chloe|Engineering| 23000| 25|\n",
      "|Helen|  Marketing| 29000| 40|\n",
      "+-----+-----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WindowFunctionsDemo\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (\"Lisa\", \"Sales\", 10000, 35),\n",
    "    (\"Evan\", \"Sales\", 32000, 38),\n",
    "    (\"Fred\", \"Engineering\", 21000, 28),\n",
    "    (\"Alex\", \"Sales\", 30000, 33),\n",
    "    (\"Tom\", \"Engineering\", 23000, 33),\n",
    "    (\"Jane\", \"Marketing\", 29000, 28),\n",
    "    (\"Jeff\", \"Marketing\", 35000, 38),\n",
    "    (\"Paul\", \"Engineering\", 29000, 23),\n",
    "    (\"Chloe\", \"Engineering\", 23000, 25),\n",
    "    (\"Helen\", \"Marketing\", 29000, 40)\n",
    "]\n",
    "\n",
    "columns = [\"name\", \"dept\", \"salary\", \"age\"]\n",
    "employees_df = spark.createDataFrame(data, columns)\n",
    "employees_df.createOrReplaceTempView(\"employees\")\n",
    "spark.sql(\"SELECT * FROM employees\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d4ee9-c032-4c74-8174-ddb5658f475d",
   "metadata": {},
   "source": [
    "### Ranking Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b5b35-fd52-468a-8c36-10153a96d237",
   "metadata": {},
   "source": [
    "RANK(): Assigns rank within the partition, with gaps if there are ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63fe2184-6f5c-4698-b550-98b1925605ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+----+\n",
      "| name|       dept|salary|rank|\n",
      "+-----+-----------+------+----+\n",
      "| Fred|Engineering| 21000|   1|\n",
      "|  Tom|Engineering| 23000|   2|\n",
      "|Chloe|Engineering| 23000|   2|\n",
      "| Paul|Engineering| 29000|   4|\n",
      "| Jane|  Marketing| 29000|   1|\n",
      "|Helen|  Marketing| 29000|   1|\n",
      "| Jeff|  Marketing| 35000|   3|\n",
      "| Lisa|      Sales| 10000|   1|\n",
      "| Alex|      Sales| 30000|   2|\n",
      "| Evan|      Sales| 32000|   3|\n",
      "+-----+-----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "       name, \n",
    "       dept, \n",
    "       salary, \n",
    "       RANK() OVER (PARTITION BY dept ORDER BY salary) AS rank \n",
    "    FROM employees\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e4785-805d-40e8-a2c0-7f732ef4494f",
   "metadata": {},
   "source": [
    "DENSE_RANK(): Assigns rank within the partition without gaps for ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99979ddc-8af4-4b83-b6d0-87406847b6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+----------+\n",
      "| name|       dept|salary|dense_rank|\n",
      "+-----+-----------+------+----------+\n",
      "| Fred|Engineering| 21000|         1|\n",
      "|  Tom|Engineering| 23000|         2|\n",
      "|Chloe|Engineering| 23000|         2|\n",
      "| Paul|Engineering| 29000|         3|\n",
      "| Jane|  Marketing| 29000|         1|\n",
      "|Helen|  Marketing| 29000|         1|\n",
      "| Jeff|  Marketing| 35000|         2|\n",
      "| Lisa|      Sales| 10000|         1|\n",
      "| Alex|      Sales| 30000|         2|\n",
      "| Evan|      Sales| 32000|         3|\n",
      "+-----+-----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "       name, \n",
    "       dept, \n",
    "       salary,\n",
    "       DENSE_RANK() OVER (PARTITION BY dept ORDER BY salary) AS dense_rank\n",
    "    FROM employees\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71afcf-1a06-4ac6-8158-d7327d116dc2",
   "metadata": {},
   "source": [
    "PERCENT_RANK() calculates the relative rank of a row within a partition:\n",
    "\n",
    "$$\n",
    "\\text{percent_rank} = \\frac{\\text{rank} - 1}{\\text{rows in partition} - 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63f59ef8-4062-4d0d-b880-86ca16ee24e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+------------------+\n",
      "| name|       dept|salary|      percent_rank|\n",
      "+-----+-----------+------+------------------+\n",
      "| Fred|Engineering| 21000|               0.0|\n",
      "|  Tom|Engineering| 23000|0.3333333333333333|\n",
      "|Chloe|Engineering| 23000|0.3333333333333333|\n",
      "| Paul|Engineering| 29000|               1.0|\n",
      "| Jane|  Marketing| 29000|               0.0|\n",
      "|Helen|  Marketing| 29000|               0.0|\n",
      "| Jeff|  Marketing| 35000|               1.0|\n",
      "| Lisa|      Sales| 10000|               0.0|\n",
      "| Alex|      Sales| 30000|               0.5|\n",
      "| Evan|      Sales| 32000|               1.0|\n",
      "+-----+-----------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "       name,\n",
    "       dept,\n",
    "       salary,\n",
    "       PERCENT_RANK() OVER (PARTITION BY dept ORDER BY salary) AS percent_rank\n",
    "    FROM employees\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a46c35-76ae-4ed2-8a8a-33cc27b54e1b",
   "metadata": {},
   "source": [
    "NTILE(N) divides the rows in each partition into N buckets of more or less equal size, and assigns each row to one of those buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d8ab6d7-722c-4fbf-954a-98969e7cde76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+-------------+\n",
      "| name|       dept|salary|salary_bucket|\n",
      "+-----+-----------+------+-------------+\n",
      "| Fred|Engineering| 21000|            1|\n",
      "|  Tom|Engineering| 23000|            1|\n",
      "|Chloe|Engineering| 23000|            2|\n",
      "| Paul|Engineering| 29000|            3|\n",
      "| Jane|  Marketing| 29000|            1|\n",
      "|Helen|  Marketing| 29000|            2|\n",
      "| Jeff|  Marketing| 35000|            3|\n",
      "| Lisa|      Sales| 10000|            1|\n",
      "| Alex|      Sales| 30000|            2|\n",
      "| Evan|      Sales| 32000|            3|\n",
      "+-----+-----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "       name,\n",
    "       dept,\n",
    "       salary,\n",
    "       NTILE(3) OVER (PARTITION BY dept ORDER BY salary) AS salary_bucket\n",
    "    FROM employees\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069df1fa-8fb8-48dd-814a-78e07013416c",
   "metadata": {},
   "source": [
    "ROW_NUMBER() assigns an incrementing integer to each row within a partition, ordered by the specified column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9f0102c-c3fc-4991-a855-cc3c844566e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+-------+\n",
      "| name|       dept|salary|row_num|\n",
      "+-----+-----------+------+-------+\n",
      "| Fred|Engineering| 21000|      1|\n",
      "|  Tom|Engineering| 23000|      2|\n",
      "|Chloe|Engineering| 23000|      3|\n",
      "| Paul|Engineering| 29000|      4|\n",
      "| Jane|  Marketing| 29000|      1|\n",
      "|Helen|  Marketing| 29000|      2|\n",
      "| Jeff|  Marketing| 35000|      3|\n",
      "| Lisa|      Sales| 10000|      1|\n",
      "| Alex|      Sales| 30000|      2|\n",
      "| Evan|      Sales| 32000|      3|\n",
      "+-----+-----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "       name,\n",
    "       dept,\n",
    "       salary,\n",
    "       ROW_NUMBER() OVER (PARTITION BY dept ORDER BY salary) AS row_num\n",
    "    FROM employees\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1efc3a2-393c-4121-b05d-9734f0668f37",
   "metadata": {},
   "source": [
    "### Analytic Functions\n",
    "\n",
    "Syntax for analytical functions are CUME_DIST(), LAG(), LEAD(), NTH_VALUE(), FIRST_VALUE(), LAST_VALUE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2ea178f-08fb-4a31-9006-12e8c9cae091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+---+------------------+\n",
      "| name|       dept|age|         cume_dist|\n",
      "+-----+-----------+---+------------------+\n",
      "| Paul|Engineering| 23|              0.25|\n",
      "|Chloe|Engineering| 25|               0.5|\n",
      "| Fred|Engineering| 28|              0.75|\n",
      "|  Tom|Engineering| 33|               1.0|\n",
      "| Jane|  Marketing| 28|0.3333333333333333|\n",
      "| Jeff|  Marketing| 38|0.6666666666666666|\n",
      "|Helen|  Marketing| 40|               1.0|\n",
      "| Alex|      Sales| 33|0.3333333333333333|\n",
      "| Lisa|      Sales| 35|0.6666666666666666|\n",
      "| Evan|      Sales| 38|               1.0|\n",
      "+-----+-----------+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "       name,\n",
    "       dept,\n",
    "       age,\n",
    "       CUME_DIST() OVER (PARTITION BY dept ORDER BY age) AS cume_dist\n",
    "    FROM employees\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f891e191-265b-4d3e-8612-689577c928b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+-----+-----+\n",
      "| name|       dept|salary|  lag| lead|\n",
      "+-----+-----------+------+-----+-----+\n",
      "| Fred|Engineering| 21000| NULL|23000|\n",
      "|  Tom|Engineering| 23000|21000|23000|\n",
      "|Chloe|Engineering| 23000|23000|29000|\n",
      "| Paul|Engineering| 29000|23000|    0|\n",
      "| Jane|  Marketing| 29000| NULL|29000|\n",
      "|Helen|  Marketing| 29000|29000|35000|\n",
      "| Jeff|  Marketing| 35000|29000|    0|\n",
      "| Lisa|      Sales| 10000| NULL|30000|\n",
      "| Alex|      Sales| 30000|10000|32000|\n",
      "| Evan|      Sales| 32000|30000|    0|\n",
      "+-----+-----------+------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "       name,\n",
    "       dept,\n",
    "       salary,\n",
    "       LAG(salary) OVER (PARTITION BY dept ORDER BY salary) AS lag,\n",
    "       LEAD(salary, 1, 0) OVER (PARTITION BY dept ORDER BY salary) AS lead\n",
    "    FROM employees\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c5fc058-2a3d-457a-b1a3-2dac8d1edbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+------------+-----------+-------------+\n",
      "| name|       dept|salary|first_salary|last_salary|second_salary|\n",
      "+-----+-----------+------+------------+-----------+-------------+\n",
      "| Fred|Engineering| 21000|       21000|      29000|        23000|\n",
      "|  Tom|Engineering| 23000|       21000|      29000|        23000|\n",
      "|Chloe|Engineering| 23000|       21000|      29000|        23000|\n",
      "| Paul|Engineering| 29000|       21000|      29000|        23000|\n",
      "| Jane|  Marketing| 29000|       29000|      35000|        29000|\n",
      "|Helen|  Marketing| 29000|       29000|      35000|        29000|\n",
      "| Jeff|  Marketing| 35000|       29000|      35000|        29000|\n",
      "| Lisa|      Sales| 10000|       10000|      32000|        30000|\n",
      "| Alex|      Sales| 30000|       10000|      32000|        30000|\n",
      "| Evan|      Sales| 32000|       10000|      32000|        30000|\n",
      "+-----+-----------+------+------------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        name,\n",
    "        dept,\n",
    "        salary,\n",
    "        \n",
    "        FIRST_VALUE(salary) OVER (\n",
    "            PARTITION BY dept\n",
    "            ORDER BY salary\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "        ) AS first_salary,\n",
    "        \n",
    "        LAST_VALUE(salary) OVER (\n",
    "            PARTITION BY dept\n",
    "            ORDER BY salary\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "        ) AS last_salary,\n",
    "        \n",
    "        NTH_VALUE(salary, 2) OVER (\n",
    "            PARTITION BY dept\n",
    "            ORDER BY salary\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "        ) AS second_salary\n",
    "        \n",
    "    FROM employees\n",
    "    ORDER BY dept, salary\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e835c93-4730-4d4e-9002-f8074f86a93c",
   "metadata": {},
   "source": [
    "### Aggregate Functions\n",
    "\n",
    "There are different aggregation functions like COUNT(), SUM(), MIN(), MAX(), AVG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bb6b0ec-fb60-4100-ad52-ee263e92958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+-----+\n",
      "| name|       dept|salary|  min|\n",
      "+-----+-----------+------+-----+\n",
      "| Fred|Engineering| 21000|21000|\n",
      "|  Tom|Engineering| 23000|21000|\n",
      "|Chloe|Engineering| 23000|21000|\n",
      "| Paul|Engineering| 29000|21000|\n",
      "| Jane|  Marketing| 29000|29000|\n",
      "|Helen|  Marketing| 29000|29000|\n",
      "| Jeff|  Marketing| 35000|29000|\n",
      "| Lisa|      Sales| 10000|10000|\n",
      "| Alex|      Sales| 30000|10000|\n",
      "| Evan|      Sales| 32000|10000|\n",
      "+-----+-----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "       name,\n",
    "       dept,\n",
    "       salary,\n",
    "       MIN(salary) OVER (PARTITION BY dept ORDER BY salary) AS min\n",
    "    FROM employees\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
